{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular Data Classification with NNI in AML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple example is to use NNI NAS 2.0(Retiarii) framework to search for the best neural architecture for tabular data classification task in Azure Machine Learning training platform.\n",
    "\n",
    "The video demo is https://www.youtube.com/watch?v=PDVqBmm7Cro and https://www.bilibili.com/video/BV1oy4y1W7GF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to prepare the dataset. Here we use the Titanic dataset as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!az login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import TitanicDataset\n",
    "from nni.retiarii import serialize\n",
    "\n",
    "train_dataset = serialize(TitanicDataset, root='./data', train=True)\n",
    "test_dataset = serialize(TitanicDataset, root='./data', train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define the Model Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model space is defined by users to express a set of models that they want to explore, which contains potentially good-performing models. In Retiarii(NNI NAS 2.0) framework, a model space is defined with two parts: a base model and possible mutations on the base model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1: Define the Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a base model is almost the same as defining a PyTorch (or TensorFlow) model. Usually, you only need to replace the code ``import torch.nn as nn`` with ``import nni.retiarii.nn.pytorch as nn`` to use NNI wrapped PyTorch modules. Below is a very simple example of defining a base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, 16)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.dropout1 = nn.Dropout(0.0)\n",
    "\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.bn2 = nn.BatchNorm1d(16)\n",
    "        self.dropout2 = nn.Dropout(0.0)\n",
    "\n",
    "        self.fc3 = nn.Linear(16, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.dropout1(F.relu(self.bn1(self.fc1(x))))\n",
    "        x = self.dropout2(F.relu(self.bn2(self.fc2(x))))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "model_space = Net(len(train_dataset.__getitem__(0)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Define the Model Mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base model is only one concrete model, not a model space. NNI provides APIs and primitives for users to express how the base model can be mutated, i.e., a model space that includes many models. The following will use inline Mutation APIs as a simple example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim1 = nn.ValueChoice(\n",
    "            [16, 32, 64, 128, 256, 512, 1024], label='hidden_dim1')\n",
    "        self.hidden_dim2 = nn.ValueChoice(\n",
    "            [16, 32, 64, 128, 256, 512, 1024], label='hidden_dim2')\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, self.hidden_dim1)\n",
    "        self.bn1 = nn.BatchNorm1d(self.hidden_dim1)\n",
    "        self.dropout1 = nn.Dropout(nn.ValueChoice([0.0, 0.25, 0.5]))\n",
    "\n",
    "        self.fc2 = nn.Linear(self.hidden_dim1, self.hidden_dim2)\n",
    "        self.bn2 = nn.BatchNorm1d(self.hidden_dim2)\n",
    "        self.dropout2 = nn.Dropout(nn.ValueChoice([0.0, 0.25, 0.5]))\n",
    "\n",
    "        self.fc3 = nn.Linear(self.hidden_dim2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.dropout1(F.relu(self.bn1(self.fc1(x))))\n",
    "        x = self.dropout2(F.relu(self.bn2(self.fc2(x))))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "model_space = Net(len(train_dataset.__getitem__(0)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides inline mutations, Retiarii also provides ``mutator``, a more general approach to express complex model space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore the Defined Model Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the NAS process, the search strategy repeatedly generates new models, and the model evaluator is for training and validating each generated model. The obtained performance of a generated model is collected and sent to the search strategy for generating better models.\n",
    "\n",
    "Users can choose a proper search strategy to explore the model space, and use a chosen or user-defined model evaluator to evaluate the performance of each sampled model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.1: Choose a Search Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-10 11:53:15] INFO (hyperopt.utils/MainThread) Failed to load dill, try installing dill via \"pip install dill\" for enhanced pickling support.\n",
      "[2021-05-10 11:53:15] INFO (hyperopt.fmin/MainThread) Failed to load dill, try installing dill via \"pip install dill\" for enhanced pickling support.\n"
     ]
    }
   ],
   "source": [
    "import nni.retiarii.strategy as strategy\n",
    "\n",
    "simple_strategy = strategy.Random()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3.2: Choose or Write a Model Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of PyTorch, Retiarii has provided two built-in model evaluators, designed for simple use cases: classification and regression. These two evaluators are built upon the awesome library PyTorch-Lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "[2021-05-10 11:53:19] INFO (lightning/MainThread) GPU available: True, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "[2021-05-10 11:53:19] INFO (lightning/MainThread) TPU available: None, using: 0 TPU cores\n",
      "C:\\Users\\win10\\anaconda3\\envs\\nni_test\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:49: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import nni.retiarii.evaluator.pytorch.lightning as pl\n",
    "\n",
    "trainer = pl.Classification(train_dataloader=pl.DataLoader(train_dataset, batch_size=16),\n",
    "                                val_dataloaders=pl.DataLoader(\n",
    "                                test_dataset, batch_size=16),\n",
    "                                max_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Configure the Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all the above are prepared, it is time to configure an experiment to do the model search. The basic experiment configuration is as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nni.retiarii.experiment.pytorch import RetiariiExeConfig, RetiariiExperiment\n",
    "\n",
    "exp = RetiariiExperiment(model_space, trainer, [], simple_strategy)\n",
    "\n",
    "exp_config = RetiariiExeConfig('aml')\n",
    "exp_config.experiment_name = 'titanic_example'\n",
    "exp_config.trial_concurrency = 2\n",
    "exp_config.max_trial_number = 20\n",
    "exp_config.max_experiment_duration = '2h'\n",
    "exp_config.experiment_working_directory = '' # an absolute path\n",
    "# exp_config.trial_gpu_number = 1\n",
    "exp_config.nni_manager_ip = ''  # your nni_manager_ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running NNI experiments on the AML(Azure Machine Learning) training service is also simple, you only need to configure the following additional fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_config.training_service.use_active_gpu = False\n",
    "exp_config.training_service.subscription_id = '' # your subscription id\n",
    "exp_config.training_service.resource_group = '' # your resource group\n",
    "exp_config.training_service.workspace_name = '' # your workspace name\n",
    "exp_config.training_service.compute_target = '' # your compute target\n",
    "exp_config.training_service.docker_image = 'kvartet/nnitest:v2.1'  # your docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run and View the Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can launch the experiment now! \n",
    "\n",
    "Besides, NNI provides WebUI to help users view the experiment results and make more advanced analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "error message in nnimanager.log:\n",
    "\n",
    "```\n",
    "[2021-05-10 11:57:07] ERROR [ 'TypeError: Converting circular structure to JSON\\n    at JSON.stringify (<anonymous>)\\n    at NNIDataStore.storeTrialJobEvent (C:\\\\Users\\\\win10\\\\anaconda3\\\\envs\\\\nni_test\\\\lib\\\\site-packages\\\\nni_node\\\\core\\\\nniDataStore.js:59:105)\\n    at NNIManager.requestTrialJobsStatus (C:\\\\Users\\\\win10\\\\anaconda3\\\\envs\\\\nni_test\\\\lib\\\\site-packages\\\\nni_node\\\\core\\\\nnimanager.js:409:38)' ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-05-10 11:53:28] Creating experiment, Experiment ID: ws9bmlnv\n",
      "[2021-05-10 11:53:28] Connecting IPC pipe...\n",
      "[2021-05-10 11:53:41] Statring web server...\n",
      "[2021-05-10 11:53:43] Setting up...\n",
      "[2021-05-10 11:53:51] Dispatcher started\n",
      "[2021-05-10 11:53:51] Web UI URLs: http://10.28.211.140:8745 http://169.254.91.194:8745 http://169.254.193.245:8745 http://192.168.30.1:8745 http://192.168.234.1:8745 http://10.28.211.140:8745 http://100.64.161.174:8745 http://127.0.0.1:8745\n",
      "[2021-05-10 11:53:52] Starting strategy...\n",
      "[2021-05-10 11:53:52] Random search running in fixed size mode. Dedup: on.\n",
      "[2021-05-10 11:53:52] Strategy started!\n",
      "GPU available: True, used: False\n",
      "[2021-05-10 11:57:02] (lightning) GPU available: True, used: False\n",
      "TPU available: None, using: 0 TPU cores\n",
      "[2021-05-10 11:57:02] (lightning) TPU available: None, using: 0 TPU cores\n",
      "C:\\Users\\win10\\anaconda3\\envs\\nni_test\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:49: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "[2021-05-10 11:57:17] Stopping experiment, please wait...\n",
      "[2021-05-10 11:57:19] Dispatcher exiting...Exception in thread \n",
      "Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\win10\\anaconda3\\envs\\nni_test\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\win10\\anaconda3\\envs\\nni_test\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\win10\\anaconda3\\envs\\nni_test\\lib\\site-packages\\nni\\retiarii\\strategy\\bruteforce.py\", line 118, in run\n",
      "    submit_models(get_targeted_model(base_model, applied_mutators, sample))\n",
      "  File \"C:\\Users\\win10\\anaconda3\\envs\\nni_test\\lib\\site-packages\\nni\\retiarii\\execution\\api.py\", line 43, in submit_models\n",
      "    engine.submit_models(*models)\n",
      "  File \"C:\\Users\\win10\\anaconda3\\envs\\nni_test\\lib\\site-packages\\nni\\retiarii\\execution\\base.py\", line 62, in submit_models\n",
      "    self._running_models[send_trial(data.dump())] = model\n",
      "  File \"C:\\Users\\win10\\anaconda3\\envs\\nni_test\\lib\\site-packages\\nni\\retiarii\\integration_api.py\", line 35, in send_trial\n",
      "    return get_advisor().send_trial(parameters)\n",
      "  File \"C:\\Users\\win10\\anaconda3\\envs\\nni_test\\lib\\site-packages\\nni\\retiarii\\integration.py\", line 106, in send_trial\n",
      "    send(CommandType.NewTrialJob, json_dumps(new_trial))\n",
      "  File \"C:\\Users\\win10\\anaconda3\\envs\\nni_test\\lib\\site-packages\\nni\\runtime\\protocol.py\", line 52, in send\n",
      "    _out_file.flush()\n",
      "OSError: [Errno 22] Invalid argument\n",
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\win10\\anaconda3\\envs\\nni_test\\lib\\threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\win10\\anaconda3\\envs\\nni_test\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\win10\\anaconda3\\envs\\nni_test\\lib\\site-packages\\nni\\retiarii\\experiment\\pytorch.py\", line 195, in _strategy_monitor\n",
      "    self._dispatcher.mark_experiment_as_ending()\n",
      "  File \"C:\\Users\\win10\\anaconda3\\envs\\nni_test\\lib\\site-packages\\nni\\retiarii\\integration.py\", line 112, in mark_experiment_as_ending\n",
      "    send(CommandType.NoMoreTrialJobs, '')\n",
      "  File \"C:\\Users\\win10\\anaconda3\\envs\\nni_test\\lib\\site-packages\\nni\\runtime\\protocol.py\", line 51, in send\n",
      "    _out_file.write(msg)\n",
      "ValueError: write to closed file\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-1394472c56d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8745\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\nni_test\\lib\\site-packages\\nni\\retiarii\\experiment\\pytorch.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, config, port, debug)\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'You are using classic search mode, config cannot be None!'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mport\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8080\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nni_test\\lib\\site-packages\\nni\\retiarii\\experiment\\pytorch.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, port, debug)\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[0m_logger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'KeyboardInterrupt detected'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nni_test\\lib\\site-packages\\nni\\retiarii\\experiment\\pytorch.py\u001b[0m in \u001b[0;36mstop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pipe\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatcher_thread\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\nni_test\\lib\\site-packages\\nni\\experiment\\pipe.py\u001b[0m in \u001b[0;36mclose\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mPipe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWindowsPipe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument"
     ]
    }
   ],
   "source": [
    "exp.run(exp_config, 8745)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Export the top Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting the top model script is also very convenient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final model:')\n",
    "for model_code in exp.export_top_models():\n",
    "    print(model_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nni_test] *",
   "language": "python",
   "name": "conda-env-nni_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "metadata": {
   "interpreter": {
    "hash": "e1266efb04e86372847b92f333cd7b31ab2b732dde1ffb66ddc0c9904b737f4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
